#!/usr/bin/env python3
import cv2
import numpy as np
import subprocess
import argparse

parser = argparse.ArgumentParser(description='Dahua Camera Motion Detection using FFmpeg')
parser.add_argument('-i', '--ip', metavar='<ip>', type=str, help="IP to connect to")
parser.add_argument('-u', '--username', metavar='<user>', type=str, help="Account username")
parser.add_argument('-p', '--password', metavar='<pass>', type=str, help="Account password")
parser.add_argument('-a', '--area', default=100, metavar='<area>', type=int, help="Contour area for detection")
parser.add_argument('-ww', '--width', default=1920, metavar='<px>', type=int, help="Window width")
parser.add_argument('-wh', '--height', default=1080, metavar='<px>', type=int, help="Window height")
parser.add_argument('-fs', '--fullscreen', action="store_true", help="Start in fullscreen mode")
parser.add_argument('-d', '--detect', action="store_true", help="Detect screen size with xrandr")
parser.add_argument('-r', '--resolution', default=0, metavar='<index>', type=int, help="Resolution index (default: 0)")
args = parser.parse_args()

if args.fullscreen:
    cv2.namedWindow('Motion', cv2.WINDOW_NORMAL)
    cv2.setWindowProperty('Motion', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)

if args.detect:
    output = subprocess.run("xrandr | grep '*' | awk '{print $1}'", shell=True, capture_output=True, text=True)
    resolutions = output.stdout.strip().split("\n")
    args.width, args.height = map(int, resolutions[args.resolution].split("x"))

def get_minimap_position(frame_dims, minimap_dims, margin=10):
    """Determine position for the minimap (always top-left for consistency)."""
    return margin, margin

def start_capture(channel):
    """Start an FFmpeg process for the specified channel."""
    print(f"Initializing FFmpeg capture on channel: {channel}")

    rtsp_url = f"rtsp://{args.username}:{args.password}@{args.ip}:554/cam/realmonitor?channel={channel}&subtype=0"

    ffmpeg_cmd = [
        "ffmpeg",
        "-rtsp_transport", "tcp",  # Use TCP for better reliability
        "-i", rtsp_url,
        "-f", "rawvideo",          # Output raw video
        "-pix_fmt", "bgr24",       # Convert to OpenCV format
        "-vsync", "drop",          # Avoid buffering lag
        "-an",                     # No audio
        "pipe:1"                   # Output to stdout
    ]

    return subprocess.Popen(ffmpeg_cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, bufsize=10**8)

def read_frame(process, width=1920, height=1080):
    """Reads a frame from an FFmpeg subprocess."""
    frame_size = width * height * 3  # BGR24 format (3 bytes per pixel)
    raw_frame = process.stdout.read(frame_size)

    if not raw_frame:
        return None

    frame = np.frombuffer(raw_frame, np.uint8).reshape((height, width, 3))
    return frame

def motion_detection():
    """Detect motion in channel 0 and switch to appropriate channel display."""
    # Initialize captures for all channels
    caps = {channel: start_capture(channel) for channel in range(1, 7)}

    # Initialize channel 0 separately for minimap
    cap0 = start_capture(0)

    # Initialize motion detection
    fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)
    current_channel = 1  # Start with channel 1

    # Define minimap size
    minimap_width = 300
    minimap_height = 160



    while True:
        # Read and process channel 0 for motion detection
        frame0 = read_frame(cap0, 704, 576)
        if frame0 is None:
            print("Error: Failed to grab frame from channel 0")
            cap0 = start_capture(0)
            continue

        # Make writable
        frame0 = frame0.copy()

        # Crop dimensions for channel 0
        crop_width = 704
        crop_height = 384
        crop_x = 0
        crop_y = 0
        frame0 = frame0[crop_y:crop_y + crop_height, crop_x:crop_x + crop_width]

        # Motion detection processing
        fgmask = fgbg.apply(frame0)
        _, thresh = cv2.threshold(fgmask, 128, 255, cv2.THRESH_BINARY)
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # Find the largest motion area
        max_area = 0
        motion_region = None
        for contour in contours:
            if cv2.contourArea(contour) > args.area:
                x, y, w, h = cv2.boundingRect(contour)
                area = w * h
                if area > max_area:
                    max_area = area
                    motion_region = (x, y, w, h)

        # Determine which channel to show based on motion position
        if motion_region:
            x, y, w, h = motion_region
            rel_x = x / crop_width
            rel_y = y / crop_height
            
            # Map position to channels 1-6
            new_channel = 1 + int(rel_x * 3) + (3 if rel_y >= 0.5 else 0)

            if new_channel != current_channel:
                print(f"Switching to channel {new_channel}")
                current_channel = new_channel

        # Read frame from current channel
        main_frame = read_frame(caps[current_channel], 1920, 1080)
        if main_frame is None:
            print(f"Error: Failed to grab frame from channel {current_channel}")
            caps[current_channel] = start_capture(current_channel)
            continue


        main_frame = main_frame.copy()  # <-- FIX: Make it writable

        # Read from other channels to avoid buffering
        for channel in range(1, 7):
            if current_channel != channel:
                _ = read_frame(caps[channel])

        # Resize minimap
        minimap = cv2.resize(frame0, (minimap_width, minimap_height))

        # Add padding around minimap
        padding = 2
        minimap_padded = cv2.copyMakeBorder(
            minimap, padding, padding, padding, padding, cv2.BORDER_CONSTANT, value=(255, 255, 255)
        )

        # Draw motion rectangle on minimap
        if motion_region:
            x, y, w, h = motion_region
            mini_scale_x = minimap_width / crop_width
            mini_scale_y = minimap_height / crop_height
            mini_rect_x = int(x * mini_scale_x)
            mini_rect_y = int(y * mini_scale_y)
            mini_rect_w = int(w * mini_scale_x)
            mini_rect_h = int(h * mini_scale_y)
            cv2.rectangle(
                minimap_padded, 
                (mini_rect_x, mini_rect_y), 
                (mini_rect_x + mini_rect_w, mini_rect_y + mini_rect_h), 
                (0, 255, 0), 
                1
            )

        # Place minimap on main display
        minimap_x, minimap_y = get_minimap_position((args.width, args.height), (minimap_padded.shape[1], minimap_padded.shape[0]))
        main_frame[minimap_y:minimap_y+minimap_padded.shape[0], minimap_x:minimap_x+minimap_padded.shape[1]] = minimap_padded
        
        cv2.imshow('Motion', main_frame)

        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key in [ord(str(i)) for i in range(1, 7)]:
            current_channel = int(chr(key))

    # Cleanup
    for cap in caps.values():
        cap.terminate()
    cap0.terminate()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    motion_detection()


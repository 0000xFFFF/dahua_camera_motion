#!/usr/bin/env python3
import cv2
import time
import sys
import numpy as np

def start_capture(ip, user, password, channel):
    """Start OpenCV VideoCapture for a given RTSP channel."""
    rtsp_url = f"rtsp://{user}:{password}@{ip}:554/cam/realmonitor?channel={channel}&subtype=0"
    cap = cv2.VideoCapture(rtsp_url)
    
    if not cap.isOpened():
        print(f"Failed to open stream for channel {channel}")
    
    return cap

def mask_timestamp(frame):
    """Mask the timestamp in the top right corner."""
    top_left = (1575, 30)
    bottom_right = (1575 + 320, 30 + 40)
    cv2.rectangle(frame, top_left, bottom_right, (0, 0, 0), -1)
    return frame

def detect_motion(frame1, frame2, threshold=128, min_area=2000, blur_size=15):
    """Detect motion between two frames with reduced sensitivity."""
    # Mask timestamps before motion detection
    frame1_masked = mask_timestamp(frame1.copy())
    frame2_masked = mask_timestamp(frame2.copy())
    
    # Convert frames to grayscale
    gray1 = cv2.cvtColor(frame1_masked, cv2.COLOR_BGR2GRAY)
    gray2 = cv2.cvtColor(frame2_masked, cv2.COLOR_BGR2GRAY)
    
    # Apply Gaussian blur to reduce noise
    gray1 = cv2.GaussianBlur(gray1, (blur_size, blur_size), 0)
    gray2 = cv2.GaussianBlur(gray2, (blur_size, blur_size), 0)
    
    # Calculate difference between frames
    frame_diff = cv2.absdiff(gray1, gray2)
    
    # Apply threshold to difference
    _, thresh = cv2.threshold(frame_diff, threshold, 255, cv2.THRESH_BINARY)
    
    # Dilate the thresholded image to fill in holes
    kernel = np.ones((5,5), np.uint8)
    thresh = cv2.dilate(thresh, kernel, iterations=1)
    
    # Apply morphological closing to remove noise
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
    
    # Find contours
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Filter contours by area
    significant_contours = [c for c in contours if cv2.contourArea(c) > min_area]
    
    # Calculate total area of motion
    motion_area = sum(cv2.contourArea(c) for c in significant_contours)
    
    # Higher threshold for total motion area
    return motion_area > (min_area * 2), significant_contours

def motion_detection(ip, user, password):
    """Detect motion in multiple RTSP streams and display accordingly."""
    
    channels = 6  # Updated to 6 channels
    caps = {i: None for i in range(channels)}
    prev_frames = {i: None for i in range(channels)}
    motion_detected = {i: False for i in range(channels)}
    display_frame = None  # Initialize display_frame
    
    # Initialize all captures
    for i in range(channels):
        print(f"Initializing capture on channel: {i}")
        caps[i] = start_capture(ip, user, password, i)
    
    current_ch = 0  # Start with channel 0
    auto_switch = True  # Flag for automatic channel switching
    
    while True:
        valid_frame_read = False  # Flag to track if we got any valid frame
        
        # Process all channels for motion
        for i in range(channels):
            if caps[i] is None:
                caps[i] = start_capture(ip, user, password, i)
                continue
                
            ret, frame = caps[i].read()
            
            if not ret:
                print(f"Failed to read frame from channel {i}, retrying...")
                caps[i].release()
                caps[i] = start_capture(ip, user, password, i)
                continue
            
            valid_frame_read = True  # We got at least one valid frame
            
            # Mask timestamp for motion detection
            frame_for_motion = frame.copy()
            
            # Initialize previous frame if needed
            if prev_frames[i] is None:
                prev_frames[i] = frame_for_motion
                continue
            
            # Detect motion
            motion, contours = detect_motion(prev_frames[i], frame_for_motion)
            motion_detected[i] = motion
            
            # Update previous frame
            prev_frames[i] = frame_for_motion
            
            # If this is the current channel, prepare it for display
            if i == current_ch:
                display_frame = frame.copy()
                
                # Draw motion indicators if motion is detected
                if motion:
                    # Draw a simplified bounding box instead of detailed contours
                    for contour in contours:
                        x, y, w, h = cv2.boundingRect(contour)
                        cv2.rectangle(display_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                
                # Add channel and motion status overlay
                #cv2.putText(display_frame, f"Channel: {current_ch}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                #cv2.putText(display_frame, f"Motion: {'Yes' if motion else 'No'}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                #cv2.putText(display_frame, f"Auto Switch: {'On' if auto_switch else 'Off'}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        
        # If we didn't get any valid frames, wait and continue
        if not valid_frame_read:
            print("No valid frames from any channel, waiting...")
            time.sleep(1)
            continue
            
        # If we don't have a display frame, skip this iteration
        if display_frame is None:
            continue
        
        # Auto-switch logic
        if auto_switch:
            # Check other channels for motion
            for i in range(1, channels):  # Skip channel 0
                if motion_detected[i]:
                    current_ch = i
                    break
            #else:  # No motion detected on any channel
            #    current_ch = 0
        
        # Display the current channel
        cv2.imshow('Motion Detection', display_frame)
        
        # Key input handling
        key = cv2.waitKey(1) & 0xFF
        if key == ord('0'): current_ch = 0
        elif key == ord('1'): current_ch = 1
        elif key == ord('2'): current_ch = 2
        elif key == ord('3'): current_ch = 3
        elif key == ord('4'): current_ch = 4
        elif key == ord('5'): current_ch = 5
        elif key == ord('a'): auto_switch = not auto_switch  # Toggle auto-switch
        elif key == ord('q'): break
    
    # Release all resources before exiting
    for cap in caps.values():
        if cap:
            cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    if len(sys.argv) != 4:
        print(f"Usage: python {sys.argv[0]} <IP> <USER> <PASS>")
        sys.exit(1)
    
    ip, user, password = sys.argv[1:]
    motion_detection(ip, user, password)
